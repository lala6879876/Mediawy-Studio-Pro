import streamlit as st
import os
import time
import requests
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from gtts import gTTS
import re

# --- 1. Ø­Ù„ÙˆÙ„ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø¬Ø°Ø±ÙŠ ---
try:
    import static_ffmpeg
    static_ffmpeg.add_paths()
except:
    pass

from moviepy.editor import ImageClip, AudioFileClip, CompositeAudioClip, concatenate_videoclips, CompositeVideoClip

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ---
BASE_PATH = os.getcwd()
MEDIA_DIR = os.path.join(BASE_PATH, "Mediawy_Studio")
ASSETS_DIR = os.path.join(MEDIA_DIR, "Assets")
VIDEOS_DIR = os.path.join(MEDIA_DIR, "Videos")
for d in [ASSETS_DIR, VIDEOS_DIR]: os.makedirs(d, exist_ok=True)

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ (Ø«Ø¨Ø§Øª Ø§Ù„Ø¹Ù†Ø§ØµØ± + Ø§Ù„ÙÙ„Ø§ØªØ±) ---
def process_static_layer(size, logo_path, marquee_text):
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    try: font = ImageFont.truetype("arial.ttf", size[1] // 25)
    except: font = ImageFont.load_default()
    if marquee_text:
        draw.rectangle([0, size[1]-80, size[0], size[1]], fill=(0,0,0,180))
        draw.text((40, size[1]-65), marquee_text, font=font, fill="white")
    if logo_path:
        logo = Image.open(logo_path).convert("RGBA").resize((size[0]//6, size[0]//6))
        img.paste(logo, (size[0] - size[0]//6 - 30, 30), logo)
    return ImageClip(np.array(img))

def create_text_clip(size, text, start_t, end_t):
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    try: font = ImageFont.truetype("arial.ttf", size[1] // 15)
    except: font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), text, font=font)
    tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]
    draw.rectangle([size[0]//2 - tw//2 - 20, size[1]//2 - th//2 - 10, 
                    size[0]//2 + tw//2 + 20, size[1]//2 + th//2 + 10], fill=(0,0,0,160))
    draw.text((size[0]//2 - tw//2, size[1]//2 - th//2), text, font=font, fill="yellow")
    return ImageClip(np.array(img)).set_start(start_t).set_end(end_t).set_position('center')

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù†Ø¸Ù…Ø© ---
st.set_page_config(page_title="Mediawy Mega V15", layout="wide")
st.markdown("<h1 style='text-align:center; color:#e60000;'>Mediawy Studio <span style='color:#00e5ff;'>V15 The Beast</span></h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("âš™ï¸ Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ…")
    dim = st.selectbox("ğŸ“ 1. Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:", ["9:16 (Shorts)", "16:9 (YouTube)"])
    edit_style = st.selectbox("ğŸ­ 2. Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙÙ†ÙŠ:", ["Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ", "Ø¯Ø±Ø§Ù…ÙŠ", "ÙˆØ«Ø§Ø¦Ù‚ÙŠ"])
    st.markdown("---")
    
    audio_source = st.radio("ğŸ¤ 3. Ù…ØµØ¯Ø± Ø§Ù„ØµÙˆØª:", ["Ø¨Ø´Ø±ÙŠ", "AI (GTTS)", "ElevenLabs"])
    el_key = st.text_input("ElevenLabs Key", type="password") if audio_source == "ElevenLabs" else ""
    el_voice = st.text_input("Voice ID", value="pNInz6obpgnu9P6ky9M8") if audio_source == "ElevenLabs" else ""
    ai_text = st.text_area("Ø§Ù„Ù†Øµ (Ø­ØªÙ‰ 500 ÙƒÙ„Ù…Ø©):", height=150)
    user_audio = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„ØµÙˆØª Ø§Ù„Ø¨Ø´Ø±ÙŠ")
    st.markdown("---")
    
    bg_music_opt = st.toggle("ğŸµ 4. Ù…ÙˆØ³ÙŠÙ‚Ù‰ + Ducking", value=True)
    ducking_strength = st.slider("ğŸ”‡ Ù‚ÙˆØ© Ø®ÙØ¶ Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰:", 0.05, 0.4, 0.1)
    st.markdown("---")
    
    img_mode = st.radio("ğŸ–¼ï¸ 5. Ø§Ù„ØµÙˆØ±:", ["Ø³ÙŠØ§Ù‚ Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ AI", "ÙŠØ¯ÙˆÙŠ (Ø¨Ø´Ø±Ù‰)"])
    user_imgs = st.file_uploader("Ø§Ø±ÙØ¹ Ø­ØªÙ‰ 500 ØµÙˆØ±Ø©", accept_multiple_files=True)
    st.markdown("---")
    
    marquee_text = st.text_input("ğŸï¸ 6. Ù†Øµ Ø§Ù„Ø¨Ù†Ø± Ø§Ù„Ø³ÙÙ„ÙŠ:", "Mediawy Studio")
    logo_file = st.file_uploader("ğŸš© 7. Ø§Ø±ÙØ¹ Ø§Ù„Ù„ÙˆØ¬Ùˆ")

# --- 5. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø´Ø§Ù…Ù„ ---
if st.button("Ø¥Ø·Ù„Ø§Ù‚ Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø´Ø§Ù…Ù„ ğŸš€", use_container_width=True):
    if not (ai_text or user_audio) or not logo_file:
        st.error("âš ï¸ Ù†Ø§Ù‚Øµ Ø¨ÙŠØ§Ù†Ø§Øª (Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ù„ÙˆØ¬Ùˆ)!")
    else:
        try:
            # Ø£- Ø§Ù„ØµÙˆØª
            status = st.info("ğŸ™ï¸ Ø¬Ø§Ø±ÙŠ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ØµÙˆØª ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚...")
            audio_p = os.path.join(ASSETS_DIR, "v.mp3")
            if audio_source == "ElevenLabs":
                res = requests.post(f"https://api.elevenlabs.io/v1/text-to-speech/{el_voice}", json={"text": ai_text}, headers={"xi-api-key": el_key})
                with open(audio_p, "wb") as f: f.write(res.content)
            elif audio_source == "AI (GTTS)": gTTS(ai_text, lang='ar').save(audio_p)
            else: 
                with open(audio_p, "wb") as f: f.write(user_audio.getbuffer())
            
            voice_clip = AudioFileClip(audio_p)
            total_dur = voice_clip.duration

            # Ø¨- ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
            sentences = re.split(r'[.ØŸ!ØŒ,]+', ai_text)
            sentences = [s.strip() for s in sentences if len(s.strip()) > 3]
            num_clips = len(sentences)
            dur_per_clip = total_dur / num_clips

            # Ø¬- Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬ (Ø²ÙˆÙˆÙ… Ø§Ù„ØµÙˆØ± ÙˆÙÙ„Ø§ØªØ± Ø§Ù„Ø£Ù„ÙˆØ§Ù†)
            h = 1080; w = int(h*9/16) if "9:16" in dim else int(h*16/9)
            img_clips = []
            sub_clips = []

            for i, sentence in enumerate(sentences):
                p = os.path.join(ASSETS_DIR, f"i_{i}.jpg")
                if img_mode == "Ø³ÙŠØ§Ù‚ Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ AI":
                    keywords = [w for w in sentence.split() if len(w) > 3]
                    search = keywords[0] if keywords else "abstract"
                    img_data = requests.get(f"https://source.unsplash.com/featured/{w}x{h}/?{search}").content
                    with open(p, "wb") as fo: fo.write(img_data)
                else:
                    with open(p, "wb") as fo: fo.write(user_imgs[i % len(user_imgs)].getbuffer())
                
                c = ImageClip(p).set_duration(dur_per_clip).resize(height=h).set_position('center')
                # ÙÙ„Ø§ØªØ± Ø§Ù„Ù†Ù…Ø·
                if edit_style == "Ø¯Ø±Ø§Ù…ÙŠ": c = c.fx(lambda clip: clip.image_transform(lambda im: (im * 0.7).astype('uint8')))
                elif edit_style == "Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ": c = c.fx(lambda clip: clip.image_transform(lambda im: (im * 1.2).astype('uint8')))
                
                # Ø²ÙˆÙˆÙ… Ù…ØªÙ†Ø§ÙˆØ¨
                z = 1.15 if i % 2 == 0 else 0.85
                c = c.resize(lambda t: 1 + (z-1) * (t/dur_per_clip)).crossfadein(0.5)
                img_clips.append(c)
                sub_clips.append(create_text_clip((w, h), sentence, i*dur_per_clip, (i+1)*dur_per_clip))

            video_track = concatenate_videoclips(img_clips, method="compose")

            # Ø¯- Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ© (Ø§Ù„Ù„ÙˆØ¬Ùˆ ÙˆØ§Ù„Ø¨Ù†Ø±)
            l_p = os.path.join(ASSETS_DIR, "l.png")
            with open(l_p, "wb") as f: f.write(logo_file.getbuffer())
            static_layer = process_static_layer((w, h), l_p, marquee_text).set_duration(total_dur)

            # Ù‡Ù€- Ø§Ù„ØµÙˆØª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (Ducking)
            if bg_music_opt:
                bg = AudioFileClip("https://www.soundhelix.com/examples/mp3/SoundHelix-Song-1.mp3").volumex(ducking_strength).set_duration(total_dur)
                final_audio = CompositeAudioClip([voice_clip.volumex(1.2), bg])
            else: final_audio = voice_clip

            # Ø§Ù„Ø±Ù†Ø¯Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            final_vid = CompositeVideoClip([video_track, static_layer] + sub_clips, size=(w, h)).set_audio(final_audio)
            out_p = os.path.join(VIDEOS_DIR, "Mediawy_Beast_V15.mp4")
            final_vid.write_videofile(out_p, fps=24, codec="libx264")
            
            st.video(out_p)
            st.success("ğŸ”¥ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…ÙƒÙ†Ø© Ø·Ù„Ø¹Øª Ù‚Ù…Ø§Ø´ ÙƒØ§Ø§Ø§Ø§Ù…Ù„ ÙˆØ¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØµØ­ÙŠØ­!")
            st.subheader("ğŸ“‹ 11. Ø¨ÙŠØ§Ù†Ø§Øª SEO")
            st.code(f"Ø§Ù„Ø§Ø³Ù…: ÙÙŠØ¯ÙŠÙˆ {edit_style} - {dim}\n#Mediawy_Studio #AI_Context #Shorts")

        except Exception as e: st.error(f"âš ï¸ Ø®Ø·Ø£: {str(e)}")
