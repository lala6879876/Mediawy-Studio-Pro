import streamlit as st
import os
import requests
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from gtts import gTTS
import re

# --- 1. Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© (MoviePy 2.x Modern) ---
import moviepy as mp
from moviepy import ImageClip, AudioFileClip, CompositeAudioClip, concatenate_videoclips, CompositeVideoClip
import moviepy.video.fx as vfx # Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­

if os.name == 'posix': 
    os.environ["IMAGEMAGICK_BINARY"] = "/usr/bin/convert"

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ---
MEDIA_DIR = "Mediawy_Studio"
ASSETS_DIR = os.path.join(MEDIA_DIR, "Assets")
VIDEOS_DIR = os.path.join(MEDIA_DIR, "Videos")
for d in [ASSETS_DIR, VIDEOS_DIR]: os.makedirs(d, exist_ok=True)

# --- 3. Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø±Ø³Ù… ÙˆØ§Ù„ØµÙˆØ± Ø§Ù„Ø°ÙƒÙŠØ© ---
def get_safe_image(path, size):
    try:
        with Image.open(path) as img:
            img.verify() 
        img = Image.open(path).convert("RGB").resize(size)
        return np.array(img)
    except:
        dummy = Image.new("RGB", size, (20, 20, 20))
        return np.array(dummy)

def create_word_clip(size, text, start_t, dur):
    if not text.strip(): text = "..."
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    try: font = ImageFont.truetype("arial.ttf", size[1] // 18)
    except: font = ImageFont.load_default()
    bbox = draw.textbbox((0, 0), text, font=font)
    tw, th = bbox[2]-bbox[0], bbox[3]-bbox[1]
    y_pos = int(size[1] * 0.75) - (th // 2)
    x_pos = (size[0] // 2) - (tw // 2)
    draw.rectangle([x_pos-20, y_pos-10, x_pos+tw+20, y_pos+th+10], fill=(0,0,0,180))
    draw.text((x_pos, y_pos), text, font=font, fill="yellow")
    return ImageClip(np.array(img)).with_start(start_t).with_duration(dur)

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù€ 11 Ø¥Ø¶Ø§ÙØ©) ---
st.set_page_config(page_title="Mediawy V51", layout="wide")
st.markdown("<h1 style='text-align:center; color:#FF0000;'>ğŸ¬ Mediawy Studio <span style='color:#00E5FF;'>V51 Fixed</span></h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("âš™ï¸ Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ…")
    dim = st.selectbox("ğŸ“ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:", ["9:16 (Shorts)", "16:9 (YouTube)"])
    edit_style = st.selectbox("ğŸ­ Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙÙ†ÙŠ:", ["Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ ğŸ¬", "Ø¯Ø±Ø§Ù…ÙŠ ğŸ­", "ÙˆØ«Ø§Ø¦Ù‚ÙŠ ğŸ“œ"])
    st.divider() # 11- ÙÙˆØ§ØµÙ„

    st.subheader("ğŸ™ï¸ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„ØµÙˆØª (Limit 500)")
    audio_source = st.radio("Ø§Ù„Ù…ØµØ¯Ø±:", ["AI (GTTS)", "ElevenLabs ğŸ’", "Ø¨Ø´Ø±ÙŠ ğŸ¤"])
    el_key, el_voice = "", ""
    if "ElevenLabs" in audio_source:
        el_key = st.text_input("ğŸ“¦ API Key", type="password")
        el_voice = st.text_input("ğŸ“¦ Voice ID", value="pNInz6obpgnu9P6ky9M8")
    
    ai_text = st.text_area("âœï¸ Ø§Ù„Ù†Øµ:", height=150)
    user_audio = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØªÙƒ")
    st.divider()

    bg_music_opt = st.toggle("ğŸµ Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø®Ù„ÙÙŠØ©", value=True)
    duck_vol = st.slider("Ù…Ø³ØªÙˆÙ‰ Ducking:", 0.05, 0.40, 0.10)
    st.divider()

    img_mode = st.radio("ğŸ–¼ï¸ Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙˆØ±:", ["Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ", "ÙŠØ¯ÙˆÙŠ"])
    user_imgs = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ùƒ", accept_multiple_files=True)
    st.divider()

    show_banner = st.toggle("ğŸš© ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ù†Ø±", value=True)
    marquee_text = st.text_input("Ù†Øµ Ø§Ù„Ø¨Ù†Ø±:")
    logo_file = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ù„ÙˆØ¬Ùˆ")

# --- 5. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ù†Ø¯Ø± Ø§Ù„Ù…Ù„ÙŠØ§Ø±ÙŠ ---
if st.button("ğŸš€ Ø¥Ø·Ù„Ø§Ù‚ Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ù…ØµÙ„Ø­", use_container_width=True):
    if not (ai_text or user_audio) or not logo_file:
        st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
    else:
        try:
            status = st.info("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬... ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø®Ø·Ø£ Ø§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª!")
            
            # [Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª]
            audio_p = os.path.join(ASSETS_DIR, "v.mp3")
            if "ElevenLabs" in audio_source:
                res = requests.post(f"https://api.elevenlabs.io/v1/text-to-speech/{el_voice}", json={"text": ai_text}, headers={"xi-api-key": el_key})
                with open(audio_p, "wb") as f: f.write(res.content)
            elif "AI" in audio_source:
                gTTS(ai_text, lang='ar').save(audio_p)
            else:
                with open(audio_p, "wb") as f: f.write(user_audio.getbuffer())
            
            voice_clip = AudioFileClip(audio_p)
            total_dur = voice_clip.duration
            sentences = [s.strip() for s in re.split(r'[.ØŸ!ØŒ,]+', ai_text) if len(s.strip()) > 2]
            dur_per_clip = total_dur / len(sentences) if sentences else total_dur

            # [Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯]
            h = 1080; w = int(h*9/16) if "9:16" in dim else int(h*16/9)
            img_clips = []
            sub_clips = []

            for i, sentence in enumerate(sentences):
                p = os.path.join(ASSETS_DIR, f"i_{i}.jpg")
                if "Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ" in img_mode:
                    img_data = requests.get(f"https://picsum.photos/seed/{i}/{w}/{h}").content
                    with open(p, "wb") as fo: fo.write(img_data)
                elif user_imgs:
                    with open(p, "wb") as fo: fo.write(user_imgs[i % len(user_imgs)].getbuffer())
                
                img_array = get_safe_image(p, (w, h))
                c = ImageClip(img_array).with_duration(dur_per_clip)
                
                # Ø¥ØµÙ„Ø§Ø­ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø²ÙˆÙˆÙ… ÙˆØ§Ù„Ù†Ù‚Ù„Ø§Øª (1, 5)
                z = 1.25 if i % 2 == 0 else 0.85
                c = c.resized(lambda t: 1 + (z-1) * (t / dur_per_clip))
                # Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† with_crossfadein Ù†Ø³ØªØ®Ø¯Ù… crossfadein Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Compose
                img_clips.append(c)
                
                # 7: Ù†ØµÙˆØµ Ù…ØªØ²Ø§Ù…Ù†Ø©
                sub_clips.append(create_word_clip((w, h), sentence, i*dur_per_clip, dur_per_clip))

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ø¹ ØªØ¯Ø§Ø®Ù„ (Crossfade) Ù†Ø§Ø¹Ù…
            video_track = concatenate_videoclips(img_clips, method="compose", padding=-0.3)

            # [8, 9] Ø§Ù„Ù‡ÙˆÙŠØ©
            l_p = os.path.join(ASSETS_DIR, "l.png")
            with open(l_p, "wb") as f: f.write(logo_file.getbuffer())
            
            static_img = Image.new("RGBA", (w, h), (0, 0, 0, 0))
            if show_banner:
                ImageDraw.Draw(static_img).rectangle([0, h-100, w, h], fill=(0,0,0,200))
                try: f_banner = ImageFont.truetype("arial.ttf", h//25)
                except: f_banner = ImageFont.load_default()
                ImageDraw.Draw(static_img).text((40, h-75), marquee_text, font=f_banner, fill="white")
            
            logo_img = Image.open(l_p).convert("RGBA").resize((w//6, w//6))
            static_img.paste(logo_img, (w-w//6-30, 30), logo_img)
            static_layer = ImageClip(np.array(static_img)).with_duration(total_dur)

            # [6] Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ùˆ Ducking
            if bg_music_opt:
                bg = AudioFileClip("https://www.soundhelix.com/examples/mp3/SoundHelix-Song-2.mp3").with_duration(total_dur).with_volume_scaled(duck_vol)
                final_audio = CompositeAudioClip([voice_clip.with_volume_scaled(1.2), bg])
            else: final_audio = voice_clip

            # Ø§Ù„Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            final_vid = CompositeVideoClip([video_track, static_layer] + sub_clips, size=(w, h)).with_audio(final_audio)
            out_p = os.path.join(VIDEOS_DIR, "Final_Fixed_V51.mp4")
            final_vid.write_videofile(out_p, fps=24, codec="libx264")
            
            st.video(out_p)
            st.success("ğŸ”¥ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…ÙƒÙ†Ø© Ø·Ù„Ø¹Øª Ù‚Ù…Ø§Ø´ ÙˆØ§Ù„Ø®Ø·Ø£ ØªÙ… Ø³Ø­Ù‚Ù‡!")
            
            # 10: SEO
            st.divider()
            st.subheader("ğŸ“‹ 10- SEO")
            st.code(f"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Ø³Ø± {sentences[0][:30]}... #Shorts #Mediawy")

        except Exception as e: st.error(f"âš ï¸ Ø®Ø·Ø£ ÙÙ†ÙŠ: {str(e)}")
