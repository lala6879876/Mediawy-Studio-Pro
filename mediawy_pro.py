import streamlit as st
import os, requests, re
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from gtts import gTTS
import moviepy as mp
from moviepy import ImageClip, AudioFileClip, CompositeAudioClip, concatenate_videoclips, CompositeVideoClip

# Ø¶Ø¨Ø· Ø§Ù„Ù…Ø­Ø±Ùƒ
if os.name == 'posix': os.environ["IMAGEMAGICK_BINARY"] = "/usr/bin/convert"

# Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
MEDIA_DIR = "Mediawy_Studio"
ASSETS_DIR = os.path.join(MEDIA_DIR, "Assets")
VIDEOS_DIR = os.path.join(MEDIA_DIR, "Videos")
for d in [ASSETS_DIR, VIDEOS_DIR]: os.makedirs(d, exist_ok=True)

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙˆØ± Ø°ÙƒÙŠØ© (4- Ø§Ù„ØµÙˆØ± Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚) ---
def get_contextual_image(query, size):
    w, h = size
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙˆØ±Ø© Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ø§Ù„ÙƒÙ„Ù…Ø© Ù„Ø¶Ù…Ø§Ù† Ø¹Ù„Ø§Ù‚ØªÙ‡Ø§ Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    search_url = f"https://source.unsplash.com/featured/{w}x{h}/?{query}"
    try:
        response = requests.get(search_url, timeout=10)
        return response.content
    except:
        # ØµÙˆØ±Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø³ØªÙ‚Ø±Ø© Ù„Ùˆ ÙØ´Ù„ Ø§Ù„Ø¨Ø­Ø«
        return requests.get(f"https://picsum.photos/{w}/{h}").content

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø²ÙˆÙˆÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ ÙˆØ§Ù„Ù†Ù‚Ù„Ø§Øª (1, 5) ---
def apply_zoom_effect(clip, mode="in"):
    """ØªØ·Ø¨ÙŠÙ‚ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø²ÙˆÙˆÙ… Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ (Ken Burns)"""
    dur = clip.duration
    if mode == "in":
        return clip.resized(lambda t: 1 + 0.2 * (t / dur)) # Ø²ÙˆÙˆÙ… Ù„Ù„Ø¯Ø§Ø®Ù„ Ù†Ø§Ø¹Ù…
    else:
        return clip.resized(lambda t: 1.2 - 0.2 * (t / dur)) # Ø²ÙˆÙˆÙ… Ù„Ù„Ø®Ø§Ø±Ø¬ Ù†Ø§Ø¹Ù…

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„ÙƒØªØ§Ø¨Ø© (7- Clipchamp Style) ---
def create_word_clip(size, text, start_t, dur):
    clean_text = str(text).strip() if text else "Mediawy"
    img = Image.new("RGBA", size, (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)
    font_size = size[0] // 15
    try: font = ImageFont.truetype("arial.ttf", font_size)
    except: font = ImageFont.load_default()
    tw = len(clean_text) * (font_size * 0.6)
    th = font_size * 1.2
    y_pos = int(size[1] * 0.72)
    x_pos = (size[0] // 2) - (int(tw) // 2)
    draw.rectangle([x_pos-20, y_pos-10, x_pos+tw+20, y_pos+th+10], fill=(0,0,0,190))
    draw.text((x_pos, y_pos), clean_text, font=font, fill="yellow")
    return ImageClip(np.array(img)).with_start(start_t).with_duration(dur)

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù€ 11 Ø¥Ø¶Ø§ÙØ©) ---
st.set_page_config(page_title="Mediawy V65", layout="wide")
st.markdown("<h1 style='text-align:center; color:#FF0000;'>ğŸ¬ Mediawy Studio <span style='color:#00E5FF;'>V65 Smart Zoom</span></h1>", unsafe_allow_html=True)

with st.sidebar:
    st.header("âš™ï¸ Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ…")
    dim = st.selectbox("ğŸ“ 2- Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:", ["9:16 (Shorts)", "16:9 (YouTube)"])
    edit_style = st.selectbox("ğŸ­ 1- Ø§Ù„Ù†Ù…Ø·:", ["Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ ğŸ¬", "Ø¯Ø±Ø§Ù…ÙŠ ğŸ­", "ÙˆØ«Ø§Ø¦Ù‚ÙŠ ğŸ“œ"])
    st.divider() # 11- ÙÙˆØ§ØµÙ„

    st.subheader("ğŸ™ï¸ 2. Ø§Ù„ØµÙˆØª")
    audio_source = st.radio("Ø§Ù„Ù…ØµØ¯Ø±:", ["AI (GTTS)", "ElevenLabs ğŸ’", "ØµÙˆØª Ø¨Ø´Ø±ÙŠ ğŸ¤"])
    ai_text = st.text_area("âœï¸ Ø§Ù„Ù†Øµ (Ø­ØªÙ‰ 500 ÙƒÙ„Ù…Ø©):", height=100)
    user_audio = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØªÙƒ Ù„Ùˆ Ø§Ø®ØªØ±Øª 'Ø¨Ø´Ø±ÙŠ'")
    st.divider()

    st.subheader("ğŸ–¼ï¸ 4. Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø°ÙƒÙŠ")
    img_mode = st.radio("Ø§Ù„Ø¬Ù„Ø¨:", ["Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ (Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰)", "Ø±ÙØ¹ ÙŠØ¯ÙˆÙŠ"])
    user_imgs = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ùƒ", accept_multiple_files=True)
    st.divider()

    show_banner = st.toggle("8- Ø§Ù„Ø¨Ù†Ø±", value=True)
    marquee_text = st.text_input("Ù†Øµ Ø§Ù„Ø¨Ù†Ø±:")
    logo_file = st.file_uploader("9- Ø§Ù„Ù„ÙˆØ¬Ùˆ")

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ---
if st.button("ğŸš€ Ø¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ù…ÙˆÙ†ØªØ§Ø¬ Ø§Ù„Ø°ÙƒÙŠ", use_container_width=True):
    try:
        status = st.info("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ ÙˆØ±Ø¨Ø· Ø§Ù„ØµÙˆØ±... ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø²ÙˆÙˆÙ… Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ...")
        
        # [Ø§Ù„ØµÙˆØª]
        audio_p = os.path.join(ASSETS_DIR, "v.mp3")
        if audio_source == "ØµÙˆØª Ø¨Ø´Ø±ÙŠ ğŸ¤" and user_audio:
            with open(audio_p, "wb") as f: f.write(user_audio.getbuffer())
        else:
            gTTS(ai_text if ai_text else "Mediawy", lang='ar').save(audio_p)
        
        voice_clip = AudioFileClip(audio_p)
        total_dur = voice_clip.duration
        sentences = [s.strip() for s in re.split(r'[.ØŸ!ØŒ,]+', ai_text) if len(s.strip()) > 1]
        dur_per_clip = total_dur / len(sentences)

        # [Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø¨Ø§Ù„Ø²ÙˆÙˆÙ… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ]
        h = 1080; w = int(h*9/16) if "9:16" in dim else int(h*16/9)
        img_clips = []
        subtitle_clips = []

        for i, sentence in enumerate(sentences):
            p = os.path.join(ASSETS_DIR, f"i_{i}.jpg")
            if img_mode == "Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒ (Ù…Ø±ØªØ¨Ø· Ø¨Ø§Ù„Ù…Ø­ØªÙˆÙ‰)":
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ„Ù…Ø© Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ù† Ø§Ù„Ø¬Ù…Ù„Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡Ø§
                query = sentence.split()[0] if len(sentence.split()) > 0 else "nature"
                img_data = get_contextual_image(query, (w, h))
                with open(p, "wb") as fo: fo.write(img_data)
            else:
                with open(p, "wb") as fo: fo.write(user_imgs[i % len(user_imgs)].getbuffer())
            
            # 1, 5: ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø²ÙˆÙˆÙ… ÙˆØ§Ù„Ù†Ù‚Ù„Ø§Øª Ø§Ù„Ù†Ø§Ø¹Ù…Ø©
            raw_img = Image.open(p).convert("RGB").resize((w, h))
            c = ImageClip(np.array(raw_img)).with_duration(dur_per_clip + 0.4) # Ø²ÙŠØ§Ø¯Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ù†Ù‚Ù„Ø©
            
            # ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† Ø²ÙˆÙˆÙ… Ø¥Ù† ÙˆØ²ÙˆÙˆÙ… Ø£ÙˆØª
            zoom_mode = "in" if i % 2 == 0 else "out"
            c = apply_zoom_effect(c, mode=zoom_mode).with_crossfadein(0.4)
            
            img_clips.append(c)
            subtitle_clips.append(create_word_clip((w, h), sentence, i*dur_per_clip, dur_per_clip))

        video_track = concatenate_videoclips(img_clips, method="compose", padding=-0.4)

        # [Ø§Ù„Ù‡ÙˆÙŠØ©]
        static_img = Image.new("RGBA", (w, h), (0, 0, 0, 0))
        if logo_file:
            logo = Image.open(logo_file).convert("RGBA").resize((w//6, w//6))
            static_img.paste(logo, (w-w//6-30, 30), logo)
        static_layer = ImageClip(np.array(static_img)).with_duration(total_dur)

        final_vid = CompositeVideoClip([video_track, static_layer] + subtitle_clips, size=(w, h)).with_audio(voice_clip)
        out_p = os.path.join(VIDEOS_DIR, "Mediawy_Smart.mp4")
        final_vid.write_videofile(out_p, fps=24, codec="libx264")
        st.video(out_p)
        
        # [10- SEO]
        st.subheader("ğŸ“‹ 10- SEO")
        st.code(f"Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {sentences[0][:40]}\n#AI #Shorts")

    except Exception as e: st.error(f"âš ï¸ Ø®Ø·Ø£: {str(e)}")
